{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bef7ab2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOGISTIC REGRESSION\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from sklearn import datasets\n",
    "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV\n",
    "from sklearn.preprocessing import StandardScaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "46729af7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load data with only two classes\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "features = iris.data[:100, :]\n",
    "target = iris.target[:100]\n",
    "\n",
    "# standardize features\n",
    "scaler = StandardScaler()\n",
    "features_standardized = scaler.fit_transform(features)\n",
    "\n",
    "# create logistic regression\n",
    "log_reg = LogisticRegression(random_state=0)\n",
    "# train model\n",
    "model = log_reg.fit(features_standardized, target)\n",
    "\n",
    "# Create new observation\n",
    "new_observation = [[.5, .5, .5, .5]]\n",
    "# predict class\n",
    "model.predict(new_observation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5daef1b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.17738424, 0.82261576]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# see probabilities\n",
    "model.predict_proba(new_observation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fe6beb33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAINING A MULTICLASS CLASSIFIER\n",
    "\n",
    "# Load data\n",
    "iris = datasets.load_iris()\n",
    "features = iris.data\n",
    "target = iris.target\n",
    "# Standardize features\n",
    "scaler = StandardScaler()\n",
    "features_standardized = scaler.fit_transform(features)\n",
    "\n",
    "# create one vs rest logistic regression\n",
    "# we can also choose multinominal version\n",
    "log_reg = LogisticRegression(random_state=0,\n",
    "                             multi_class='ovr')\n",
    "# train model\n",
    "model = log_reg.fit(features_standardized, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eac191e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# REDUCE VARIANCE THROUGH REGULARIZATION\n",
    "\n",
    "# load data\n",
    "iris = datasets.load_iris()\n",
    "features = iris.data\n",
    "target = iris.target\n",
    "\n",
    "# standardize features\n",
    "scaler = StandardScaler()\n",
    "features_standardized = scaler.fit_transform(features)\n",
    "\n",
    "# create log_reg with cross validation\n",
    "log_reg = LogisticRegressionCV(penalty='l2',\n",
    "                              Cs=10,\n",
    "                              random_state=0,\n",
    "                              n_jobs=-1)\n",
    "\n",
    "# train model\n",
    "model = log_reg.fit(features_standardized, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1ffc069a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAINING A CLASSIFIER ON VERY LARGE DATA\n",
    "\n",
    "# load data\n",
    "iris = datasets.load_iris()\n",
    "features = iris.data\n",
    "target = iris.target\n",
    "\n",
    "# standardize features\n",
    "scaler = StandardScaler()\n",
    "features_standardized = scaler.fit_transform(features)\n",
    "\n",
    "# create logistic regression\n",
    "log_reg = LogisticRegression(random_state=0,\n",
    "                            solver='sag')\n",
    "# sag - stochastic average gradient for big datasets\n",
    "\n",
    "# train model\n",
    "model = log_reg.fit(features_standardized, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8504179f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HANDLING IMBALANCED CLASSES\n",
    "\n",
    "# load data\n",
    "iris = datasets.load_iris()\n",
    "features = iris.data\n",
    "target = iris.target\n",
    "\n",
    "# make imbalance\n",
    "features = features[40:, :]\n",
    "target = target[40:]\n",
    "\n",
    "# create target vector indicating if class 0, otherwise 1\n",
    "target = np.where((target==0), 0, 1)\n",
    "\n",
    "# standardize features\n",
    "scaler = StandardScaler()\n",
    "features_standardized = scaler.fit_transform(features)\n",
    "\n",
    "# create logistic regression\n",
    "log_reg = LogisticRegression(random_state=0,\n",
    "                            class_weight='balanced')\n",
    "\n",
    "# train model\n",
    "model = log_reg.fit(features_standardized, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a185570",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
